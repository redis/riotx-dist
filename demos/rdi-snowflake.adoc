= ğŸ”ï¸ Snowflake CDC with RDI and RIOT-X
:rdi-version: 1.12.3
:rdi-pass: admin123
:rdi-jwt: CwxMR2btWRxlIWaF89f4NuCfPXFtDb3pTUqI3YnZUB0=

This comprehensive guide provides step-by-step instructions for setting up real-time Change Data Capture (CDC) from Snowflake to Redis using Redis Data Integration (RDI) and RIOT-X.
It uses Google Kubernetes Engine (https://cloud.google.com/kubernetes-engine?hl=en[GKE]) to deploy all the components involved.

[TIP]
====
â±ï¸ **Estimated completion time:** 45-60 minutes

ğŸ“‹ **What you'll build:** A complete CDC pipeline that captures changes from Snowflake and streams them to Redis in real-time
====

== ğŸ“‹ Prerequisites

Before starting, ensure you have:

1. â˜ï¸ **Google Cloud account** with billing enabled
2. â„ï¸ **Snowflake account** - Register for a https://signup.snowflake.com[free trial] if needed
3. ğŸ” **https://redis.io/insight/[Redis Insight]** installed on your local machine

== â˜¸ï¸ GKE and Redis Enterprise Setup

First, we'll set up our Kubernetes infrastructure and Redis databases.

Follow the guide at https://github.com/redis-field-engineering/re-k8s-on-gke-quickstart[re-k8s-on-gke-quickstart] to:

1. ğŸ—ï¸ **Create a GKE cluster** with appropriate node pools
2. ğŸš€ **Deploy Redis Enterprise** operator and cluster
3. ğŸ¯ **Create the target Redis database** for storing CDC data

[[_target_db]]
=== ğŸ¯ Target Redis Database

[IMPORTANT]
====
âš™ï¸ **Configuration adjustments needed:**

For this demo, modify `redis-database.yaml` to use minimal resources and disable TLS for simplicity:

[source,yaml]
----
  memorySize: 1GB
  shardCount: 1
  # ...
  tlsMode: "disabled"
----

ğŸ’¡ This configuration is suitable for development/testing. For production, consider enabling TLS and scaling resources appropriately.
====

âœ… **Verify the Redis database creation** and save the connection details for later use:

[source,console]
----
./scripts/get-redis-ui-credentials.sh
ğŸ”‘ Redis Enterprise Web UI Credentials
=====================================
...
----

=== ğŸ—ƒï¸ RDI State Database

RDI requires its own dedicated Redis database to store pipeline state and metadata.

1. **Create the RDI state database** using the following configuration:
+
.`redis-rdi.yaml`
[source,yaml]
----
apiVersion: app.redislabs.com/v1alpha1
kind: RedisEnterpriseDatabase
metadata:
  name: redis-rdi
  namespace: redis-enterprise
spec:
  # Redis Enterprise Cluster reference
  redisEnterpriseCluster:
    name: redis-enterprise-cluster
  memorySize: 1GB
  shardCount: 1
  replication: true
  evictionPolicy: noeviction
  persistence: aofEverySecond
  shardsPlacement: sparse
  proxyPolicy: all-nodes

  # Database configuration
  databasePort: 12001
  databaseSecretName: redis-db-sample-secret

  # TLS configuration
  tlsMode: "disabled"
----

2. **Deploy the RDI database** to your cluster:
+
[source,console]
----
kubectl apply -f redis-rdi.yaml
----

3. âœ… **Verify deployment** and save the connection details:
+
[source,console]
----
./scripts/get-redis-ui-credentials.sh
ğŸ”‘ Redis Enterprise Web UI Credentials
=====================================
...
----


== ğŸ”„ RDI Installation

Now we'll deploy Redis Data Integration (RDI) on our GKE cluster. We'll use a subset of the official RDI Kubernetes installation steps from the https://redis.io/docs/latest/integrate/redis-data-integration/installation/install-k8s/[official documentation].

1. ğŸ“¥ **Download the RDI Helm chart:**
+
[source,console,subs="verbatim,attributes"]
----
wget https://redis-enterprise-software-downloads.s3.amazonaws.com/redis-di/rdi-{rdi-version}.tgz
----

2. ğŸ“ **Create a custom values file** for our GKE deployment:
+
.`rdi-values.yaml`
[source,yaml,subs="verbatim,attributes"]
----
global:
  vmMode: false
  openShift: false
  logLevel: INFO
  image:
    registry: docker.io
    repository: redis
    tag: {rdi-version}
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    runAsGroup: 1000
    allowPrivilegeEscalation: false
  createSecrets: true
  externalSecrets:
    enabled: false
connection:
  host: "redis-rdi-load-balancer.redis-enterprise.svc.cluster.local"
  port: "12001"
  username: ""
  password: "{rdi-pass}"
  ssl:
    enabled: false
reloader:
  reloader:
    watchGlobally: false
    isOpenshift: false
    deployment:
      containerSecurityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
            - ALL
      securityContext:
        runAsUser: null
  fullnameOverride: rdi-reloader
operator:
  image:
    name: rdi-operator
    pullPolicy: IfNotPresent
  liveness:
    failureThreshold: 3
    periodSeconds: 20
  readiness:
    failureThreshold: 3
    periodSeconds: 10
  startup:
    failureThreshold: 24
    periodSeconds: 5

  dataPlane:
    collector:
      image:
        registry: docker.io
        repository: redislabs/debezium-server
        tag: 3.0.8.Final-rdi.1
      initializer:
        image:
          name: rdi-collector-initializer
      service:
        type: ClusterIP
        port: 9092
      serviceMonitor:
        enabled: false
      serviceAccount:
        enabled: true
      ingress:
        enabled: false
        pathPrefix: "/metrics"
    collectorApi:
      enabled: true
fluentd:
  image:
    name: rdi-fluentd
    pullPolicy: IfNotPresent
  rdiLogsHostPath: "/opt/rdi/logs"
  podLogsHostPath: "/var/log/pods"
  logrotateMinutes: "5"
rdiMetricsExporter:
  image:
    name: rdi-monitor
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 9121
  liveness:
    failureThreshold: 6
    periodSeconds: 10
  readiness:
    failureThreshold: 6
    periodSeconds: 30
  startup:
    failureThreshold: 60
    periodSeconds: 5
  serviceMonitor:
    enabled: false
  ingress:
    enabled: false
    pathPrefix: "/metrics"
api:
  image:
    name: rdi-api
    pullPolicy: IfNotPresent
  jwtKey: "{rdi-jwt}"
  service:
    type: ClusterIP
    port: 8080
    targetPort: 8081
  liveness:
    failureThreshold: 6
    periodSeconds: 10
  readiness:
    failureThreshold: 6
    periodSeconds: 30
  startup:
    failureThreshold: 60
    periodSeconds: 5
ingress:
  enabled: true
  className: "nginx"
  tls:
    enabled: false
route:
  enabled: false
  tls:
    enabled: false
----

3. ğŸš€ **Install RDI using Helm:**
+
[source,console,subs="verbatim,attributes"]
----
helm upgrade --install rdi rdi-{rdi-version}.tgz -f rdi-values.yaml -n rdi --create-namespace
----

4. âœ… **Verify the RDI installation:**
+
[source,console]
----
helm list -n rdi
----
+
Expected output:
+
[source,console,subs="verbatim,attributes"]
----
NAME    NAMESPACE       REVISION        UPDATED         STATUS          CHART           APP VERSION
default rdi             5               2025-08-14 ...  deployed        pipeline-0.1.0  0.0.0
rdi     rdi             9               2025-08-13 ...  deployed        rdi-{rdi-version}
----
+
ğŸ” **Check pod status** - all pods should be in `Running` state:
+
[source,console,subs="verbatim,attributes"]
----
kubectl get pod -n rdi

NAME                                    READY   STATUS      RESTARTS      AGE
processor-8b64ccb69-nwmgb               1/1     Running     0             18h
rdi-api-f59db875f-bcvcv                 1/1     Running     0             21h
rdi-metrics-exporter-6b55698c9f-bfpxf   1/1     Running     0             21h
rdi-operator-745854864f-shn7r           1/1     Running     1 (12h ago)   21h
rdi-reloader-546c9cd849-2zq98           1/1     Running     0             41h
----

5. ğŸŒ **Get the RDI API external IP** (you'll need this for Redis Insight):
+
[source,console]
----
kubectl describe ingress rdi-api -n rdi

Name:             rdi-api
Labels:           app=rdi-api
                  app.kubernetes.io/managed-by=Helm
                  product=rdi
Namespace:        rdi
Address:          35.233.236.75   # <1>
Ingress Class:    nginx
Default backend:  <default>
Rules:
  Host        Path  Backends
  ----        ----  --------
  *
              /   rdi-api:8080 (10.1.2.29:8081)
Annotations:  meta.helm.sh/release-name: rdi
              meta.helm.sh/release-namespace: rdi
Events:       <none>
----
<1> RDI API external IP address

== ğŸ” Redis Insight Configuration

=== ğŸ”§ RDI Pipeline Setup

Now we'll configure our CDC pipeline using Redis Insight.

1. ğŸ”— **Add RDI endpoint:**
+
In Redis Insight, navigate to `Redis Data Integration` and create a new endpoint with these settings:
+
[horizontal,subs="verbatim,attributes"]
----
RDI Alias:: `gke`
URL:: `https://<external_ip>/`
Username:: `default`
Password:: `{rdi-pass}`
----
+
ğŸ“„ **Set up the pipeline configuration:**
+
Click on `Configuration file` and paste this YAML configuration:
+
[source,yaml,subs="verbatim,attributes"]
----
sources:
  riotx:
    type: external
    connection: {}

targets:
  target:
    connection:
      type: redis
      host: redis-db-sample-load-balancer.redis-enterprise.svc.cluster.local
      port: 12000
      password: {rdi-pass}
----

2. âš¡ **Create the CDC job:**
+
Click the `+` button next to *Jobs*, name it `orders`, and add this job configuration:
+
[source,yaml]
----
name: orders
source:
  table: incremental_order_header

output:
  - uses: redis.write
    with:
      connection: target
      data_type: hash
      key:
        expression: concat(['order:', ORDER_ID])
        language: jmespath
----

3. ğŸš€ **Deploy the pipeline:**
+
[IMPORTANT]
====
Click **Deploy Pipeline**, make sure to check the **Reset** checkbox (this clears any existing state), then click **Deploy**.

â³ Wait for the deployment to complete before proceeding to the next step.
====

== â„ï¸ Snowflake Configuration

=== ğŸ—„ï¸ Database and Schema Setup

We'll use a Snowflake notebook to set up our environment with sample data.

1. ğŸ““ **Import the setup notebook:**
+
In your https://quickstarts.snowflake.com/guide/getting_started_with_snowflake_notebooks/index.html?index=..%2F..index#1[Snowflake UI (Snowsight)], import this notebook: https://redis.github.io/riotx/snowflake-cdc.ipynb[snowflake-cdc.ipynb]

2. ğŸƒ **Run the initial setup steps:**
+
Execute only these first two notebook cells:
+
[horizontal]
`init`:: ğŸ—ï¸ Sets up roles, permissions, and schema structure
`populate`:: ğŸ“Š Creates and populates the `incremental_order_header` table with sample data

[CAUTION]
====
â›” **Stop here!** Do not run the remaining notebook steps yet - we'll use them later to test our CDC pipeline.
====

=== ğŸ” Key-pair Authentication Setup

Snowflake key-pair authentication provides secure, passwordless access for RIOT-X.

ğŸ“š Follow the detailed steps in the https://docs.snowflake.com/en/user-guide/key-pair-auth[Snowflake key-pair authentication documentation].

[TIP]
====
ğŸ’¾ **Save your private key** in a secure location (e.g., `~/.ssh/snowflake_key.p8`) - you'll need it in the next section.
====

== ğŸš€ RIOT-X External Collector

RIOT-X will act as our external collector, monitoring Snowflake for changes and feeding them into the RDI pipeline.

[INFO]
====
ğŸ¯ **What's happening here:** RIOT-X connects to Snowflake using CDC capabilities and streams changes to RDI, which then processes and forwards them to our target Redis database.
====

1. ğŸ› ï¸ **Install k8s-run tool:**
+
Install `k8r` from https://github.com/jeremyplichta/k8s-run[k8s-run] to easily run containers in Kubernetes.

2. ğŸ”’ **Configure secrets for secure access:**
+
[source,console,subs="verbatim,attributes"]
----
k8r secret --job-name riotx snowflake_key.p8 ~/.ssh/snowflake_key.p8
k8r secret --job-name riotx redis_pass {rdi-pass}
----

3. ğŸš€ **Launch the RIOT-X collector:**
+
[IMPORTANT]
====
ğŸ“ **Before running:** Replace `<account>` with your Snowflake account identifier and `<user>` with your Snowflake username.
====
+
[source,console]
----
k8r run --rm --job-name riotx -d riotx/riotx:latest -- riotx snowflake-import --progress log --host redis-rdi-load-balancer.redis-enterprise.svc.cluster.local --port 12001 --pass '$REDIS_PASS' --role riotx_cdc --warehouse compute_wh --cdc-schema raw_pos_cdc --jdbc-url "jdbc:snowflake://<account>.snowflakecomputing.com?private_key_file=/k8r/secrets/snowflake_key.p8" --jdbc-user <user> --offset-clear tb_101.raw_pos.incremental_order_header
----

== ğŸ§ª Testing CDC Operations

Time to test our complete CDC pipeline! We'll verify that changes in Snowflake are automatically captured and replicated to Redis.

[INFO]
====
âœ¨ **What to expect:** As you make changes in Snowflake, you should see corresponding updates in Redis within seconds, demonstrating continuous data synchronization.
====

1. ğŸ”— **Connect to your target Redis database:**
+
In Redis Insight, add a connection to the <<_target_db, target Redis database>> you created earlier.

2. ğŸ“¸ **Initial Snapshot Test:**
+
âœ… Verify that your target Redis database contains exactly `100` keys (matching the initial Snowflake table row count).
+
[TIP]
====
ğŸ” In Redis Insight, use the "Keys" view to see all `order:*` keys that were created from the initial data snapshot.
====

3. â• **Insert Operation Test:**
+
â–¶ï¸ Return to your Snowflake notebook and run the `additional_data` step
+
âœ… Verify the target Redis database now contains `200` total keys (original 100 + new 100)

4. âœï¸ **Update Operation Test:**
+
â–¶ï¸ Run the `update` step in the Snowflake notebook
+
âœ… Check that the corresponding Redis hash key is updated with the new values

5. ğŸ—‘ï¸ **Delete Operation Test:**
+
â–¶ï¸ Run the `delete` step in the Snowflake notebook
+
âœ… Confirm the corresponding key is removed from the Redis database

[NOTE]
====
ğŸ‰ **Congratulations!** If all tests pass, you've successfully set up a complete real-time CDC pipeline from Snowflake to Redis using RDI and RIOT-X.

ğŸ“ˆ **Next steps:** Consider exploring RDI's advanced features like data transformations, filtering, and monitoring capabilities.
====




